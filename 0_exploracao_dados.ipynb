{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime as dt\n",
    "from bs4 import BeautifulSoup\n",
    "from utils._funcs import creating_club_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Club name and id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To make the request to the page we have to inform the\n",
    "website that we are a browser and that is why we\n",
    "use the headers variable\n",
    "\"\"\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'}\n",
    "\n",
    "# def creating_club_dataframe(\n",
    "#         club_name, \n",
    "#         club_id, \n",
    "#         headers\n",
    "#     ):\n",
    "\n",
    "#     # endereco_da_pagina stands for the data page address\n",
    "#     endereco_da_pagina = \"https://www.transfermarkt.com.br/\"+club_name+\"/startseite/verein/\"+club_id+\"?saison_id=2021\"\n",
    "\n",
    "#     # In the objeto_response variable we will the download of the web page\n",
    "#     objeto_response = requests.get(endereco_da_pagina, headers=headers)\n",
    "\n",
    "#     \"\"\"\n",
    "#     Now we will create a BeautifulSoup object from our object_response.\n",
    "#     The 'html.parser' parameter represents which parser we will use when creating our object,\n",
    "#     a parser is a software responsible for converting an entry to a data structure.\n",
    "#     \"\"\"\n",
    "#     pagina_bs = BeautifulSoup(objeto_response.content, 'html.parser')\n",
    "\n",
    "#     club_jog = [] # List that will receive all the players club - \n",
    "\n",
    "#     transfmkt_site = 'https://www.transfermarkt.com.br'\n",
    "\n",
    "#     # Players names\n",
    "#     nomes_jog = [] # List that will receive all the players names - check\n",
    "#     tags_nomes = pagina_bs.find_all(\"span\", {\"class\": \"show-for-small\"})\n",
    "#     for tag_nome in tags_nomes:\n",
    "#         nomes_jog.append(tag_nome.text)\n",
    "\n",
    "#     # Players links\n",
    "#     links_jog = [] # List that will receive all the players profile links - check\n",
    "#     tags_links = BeautifulSoup(str(tags_nomes).strip('[]'), 'html.parser')\n",
    "#     for a in tags_links.find_all('a', href=True):\n",
    "#         links_jog.append(a['href'])\n",
    "\n",
    "#     # Players Values links\n",
    "#     links_values_jog = []\n",
    "#     for link in links_jog:\n",
    "#         links_values_jog.append(str(link).replace(\"profil\",\"marktwertverlauf\"))\n",
    "\n",
    "#     # Players clubs\n",
    "#     club_name_of = club_name.replace(\"-\",\"_\")\n",
    "#     club_jog = [] # List that will receive all the players club - check\n",
    "#     for c in range(len(nomes_jog)):\n",
    "#         club_jog.append(club_name_of)\n",
    "\n",
    "#     # Clubs championship\n",
    "#     camp_jog = []\n",
    "#     tags_camp = pagina_bs.find_all(\"span\", {\"class\": \"hauptpunkt\"})\n",
    "#     for tag_camp in tags_camp:\n",
    "#         camp = str(tag_camp.text).replace(\" \", \"\").replace(\"\\n\",\"\")\n",
    "\n",
    "#     for c in range(len(nomes_jog)):\n",
    "#         camp_jog.append(camp)\n",
    "\n",
    "#     # Players Positions\n",
    "#     posicoes_jog = [] # List that will receive all the players positions - check\n",
    "#     tags_goleiros = pagina_bs.find_all(\"td\", {\"class\": \"zentriert rueckennummer bg_Torwart\"})\n",
    "#     tags_zagueiros = pagina_bs.find_all(\"td\", {\"class\": \"zentriert rueckennummer bg_Abwehr\"})\n",
    "#     tags_meias = pagina_bs.find_all(\"td\", {\"class\": \"zentriert rueckennummer bg_Mittelfeld\"})\n",
    "#     tags_atacantes = pagina_bs.find_all(\"td\", {\"class\": \"zentriert rueckennummer bg_Sturm\"})\n",
    "\n",
    "#     # Gk positions\n",
    "#     for c in range(len(tags_goleiros)):\n",
    "#         posicoes_jog.append(\"Goleiro\")\n",
    "\n",
    "#     # Defenders positions\n",
    "#     for c in range(len(tags_zagueiros)):\n",
    "#         posicoes_jog.append(\"Defensor\")\n",
    "\n",
    "#     # Midfielders positions\n",
    "#     for c in range(len(tags_meias)):\n",
    "#         posicoes_jog.append(\"Meia\")\n",
    "\n",
    "#     # Strikers positions\n",
    "#     for c in range(len(tags_atacantes)):\n",
    "#         posicoes_jog.append(\"Atacante\")\n",
    "\n",
    "#     # Players age, heights, nacionalities\n",
    "#     idade_jog = [] # List that will receive all the players age - check\n",
    "#     alt_jog = [] # List that will receive all the players height - check\n",
    "#     nac_jog = [] # List that will receive all the players nacionalities - check\n",
    "\n",
    "#     for link in links_jog:\n",
    "#         end = transfmkt_site + link\n",
    "#         obj_resp = requests.get(end, headers=headers)\n",
    "#         pag_bs = BeautifulSoup(obj_resp.content, 'html.parser')\n",
    "#         tags_idades = pag_bs.find_all(\"span\", {\"itemprop\": \"birthDate\"})\n",
    "#         tags_nac = pag_bs.find_all(\"span\", {\"itemprop\": \"nationality\"})\n",
    "#         tags_alt = pag_bs.find_all(\"span\", {\"itemprop\": \"height\"})\n",
    "#         for tag_idade in tags_idades:\n",
    "#             idade_jog.append(str(tag_idade.text).replace(\" \", \"\")[12:14])\n",
    "\n",
    "#         for tag_nac in tags_nac:\n",
    "#             nac_jog.append(str(tag_nac.text).replace(\" \", \"\")[1:])\n",
    "\n",
    "#         for tag_alt in tags_alt:\n",
    "#             alt_jog.append(float(str(tag_alt.text).replace(\",\",\".\")[:5].rstrip()))\n",
    "\n",
    "#     # Players performance\n",
    "#     gols_jog = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Players value\n",
    "#     valor_jog = []\n",
    "\n",
    "\n",
    "    \n",
    "#     dic = {\n",
    "#         'nome':nomes_jog,\n",
    "#         'clube_atual':club_jog,\n",
    "#         'campeonato':camp_jog,\n",
    "#         'posicao':posicoes_jog,\n",
    "#         'idade':idade_jog,\n",
    "#         'nacionalidade':nac_jog,\n",
    "#         'altura':alt_jog\n",
    "#     }\n",
    "\n",
    "#     df = pd.DataFrame(dic)\n",
    "\n",
    "#     # Players transfers links\n",
    "#     link_transfers_jog = []\n",
    "#     for link in links_values_jog:\n",
    "#         link_transfers_jog.append(link.replace('marktwertverlauf','transfers'))\n",
    "\n",
    "#     # Players Seasons\n",
    "#     temps_all = []\n",
    "#     for link in link_transfers_jog:\n",
    "#         end = transfmkt_site + link\n",
    "#         obj_resp = requests.get(end, headers=headers)\n",
    "#         pag_bs = BeautifulSoup(obj_resp.content, 'html.parser')\n",
    "#         tags_seasons = pag_bs.find_all(\"div\", {\"class\": \"tm-player-transfer-history-grid__season\"})\n",
    "#         for tag in tags_seasons:\n",
    "#             temps_all.append(str(tag.text).replace(\" \", \"\").replace(\"\\n\",\"\"))\n",
    "\n",
    "#     cont = temps_all.count('Temporada')\n",
    "#     idxs = []\n",
    "#     c = 0\n",
    "#     temps_jog = []\n",
    "\n",
    "#     for d in range(0,cont):\n",
    "#         i = temps_all.index('Temporada',c)\n",
    "#         c = i + 1\n",
    "#         idxs.append(i)\n",
    "#         c = i + 1\n",
    "#     idxs.append(len(temps_all))\n",
    "#     idxs.pop(0)\n",
    "\n",
    "#     c = 0\n",
    "#     for d in range(0,cont):\n",
    "#         part = temps_all[c:idxs[d]]\n",
    "#         temps_jog.append(part)\n",
    "#         c += len(part)\n",
    "\n",
    "#     for lst in temps_jog:\n",
    "#         lst.pop(0)\n",
    "\n",
    "#     for lst in temps_jog:\n",
    "#         if len(lst) == 0:\n",
    "#             lst.append('22/23')\n",
    "#         else:\n",
    "#             pass\n",
    "\n",
    "    \n",
    "#     return temps_jog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 3], [3, 3, 3], [3], [3, 3, 3, 3, 3, 3], [3], [3, 3]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst1 = [1,3,3,1,3,3,3,1,3,1,3,3,3,3,3,3,1,1,3,3]\n",
    "cont = lst1.count(1)\n",
    "idxs = []\n",
    "c = 0\n",
    "lst2 = []\n",
    "\n",
    "for d in range(0,cont):\n",
    "    i = lst1.index(1,c)\n",
    "    c = i + 1\n",
    "    idxs.append(i)\n",
    "    c = i + 1\n",
    "idxs.append(len(lst1))\n",
    "idxs.pop(0)\n",
    "\n",
    "c = 0\n",
    "for d in range(0,cont):\n",
    "    part = lst1[c:idxs[d]]\n",
    "    lst2.append(part)\n",
    "    c += len(part)\n",
    "\n",
    "for lst in lst2:\n",
    "    lst.pop(0)\n",
    "\n",
    "for lst in lst2:\n",
    "    if len(lst) == 0:\n",
    "        lst.append(3)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "temp1_jog = []\n",
    "\n",
    "\n",
    "lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['17/18',\n",
       "  '11/12',\n",
       "  '09/10',\n",
       "  '09/10',\n",
       "  '09/10',\n",
       "  '08/09',\n",
       "  '08/09',\n",
       "  '08/09',\n",
       "  '07/08',\n",
       "  '06/07',\n",
       "  '05/06'],\n",
       " ['21/22', '16/17', '15/16', '14/15', '11/12', '11/12', '10/11'],\n",
       " ['19/20', '18/19', '18/19', '17/18', '14/15'],\n",
       " ['20/21', '19/20', '18/19', '16/17', '14/15', '11/12'],\n",
       " ['21/22', '19/20', '16/17'],\n",
       " ['16/17', '13/14'],\n",
       " ['19/20'],\n",
       " ['20/21', '14/15', '14/15', '14/15'],\n",
       " ['21/22', '19/20', '19/20', '16/17'],\n",
       " ['21/22',\n",
       "  '20/21',\n",
       "  '20/21',\n",
       "  '19/20',\n",
       "  '18/19',\n",
       "  '18/19',\n",
       "  '18/19',\n",
       "  '16/17',\n",
       "  '14/15'],\n",
       " ['22/23'],\n",
       " ['18/19',\n",
       "  '18/19',\n",
       "  '17/18',\n",
       "  '11/12',\n",
       "  '09/10',\n",
       "  '09/10',\n",
       "  '09/10',\n",
       "  '07/08',\n",
       "  '07/08',\n",
       "  '07/08'],\n",
       " ['18/19', '18/19', '16/17', '12/13'],\n",
       " ['22/23', '19/20'],\n",
       " ['20/21', '20/21', '18/19'],\n",
       " ['21/22', '20/21', '18/19', '15/16', '15/16'],\n",
       " ['21/22', '19/20'],\n",
       " ['19/20'],\n",
       " ['18/19', '16/17', '16/17', '15/16', '15/16', '14/15', '13/14', '13/14'],\n",
       " ['21/22', '18/19', '18/19', '17/18'],\n",
       " ['18/19', '17/18', '16/17'],\n",
       " ['17/18', '17/18', '17/18', '14/15', '14/15', '13/14'],\n",
       " ['20/21', '20/21', '14/15', '14/15', '13/14', '11/12', '10/11', '09/10'],\n",
       " ['19/20', '19/20', '18/19'],\n",
       " ['21/22', '20/21'],\n",
       " ['22/23', '20/21', '16/17'],\n",
       " ['20/21',\n",
       "  '19/20',\n",
       "  '19/20',\n",
       "  '19/20',\n",
       "  '19/20',\n",
       "  '18/19',\n",
       "  '16/17',\n",
       "  '16/17',\n",
       "  '15/16'],\n",
       " ['22/23', '21/22'],\n",
       " ['19/20', '18/19', '17/18', '16/17', '16/17', '15/16', '14/15'],\n",
       " ['22/23', '20/21', '18/19', '16/17'],\n",
       " ['21/22', '19/20', '19/20', '17/18'],\n",
       " ['22/23',\n",
       "  '21/22',\n",
       "  '21/22',\n",
       "  '20/21',\n",
       "  '18/19',\n",
       "  '18/19',\n",
       "  '17/18',\n",
       "  '17/18',\n",
       "  '17/18',\n",
       "  '17/18',\n",
       "  '16/17',\n",
       "  '16/17']]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To make the request to the page we have to inform the\n",
    "website that we are a browser and that is why we\n",
    "use the headers variable\n",
    "\"\"\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'}\n",
    "\n",
    "df = creating_club_dataframe('se-palmeiras','1023', headers)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To make the request to the page we have to inform the\n",
    "website that we are a browser and that is why we\n",
    "use the headers variable\n",
    "\"\"\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36'}\n",
    "\n",
    "# endereco_da_pagina stands for the data page address\n",
    "endereco_da_pagina = \"https://www.transfermarkt.com.br/america-mineiro/startseite/verein/2863?saison_id=2021\"\n",
    "\n",
    "# In the objeto_response variable we will the download of the web page\n",
    "objeto_response = requests.get(endereco_da_pagina, headers=headers)\n",
    "\n",
    "\"\"\"\n",
    "Now we will create a BeautifulSoup object from our object_response.\n",
    "The 'html.parser' parameter represents which parser we will use when creating our object,\n",
    "a parser is a software responsible for converting an entry to a data structure.\n",
    "\"\"\"\n",
    "pagina_bs = BeautifulSoup(objeto_response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "club_jog = [] # List that will receive all the players club - \n",
    "\n",
    "transfmkt_site = 'https://www.transfermarkt.com.br'\n",
    "\n",
    "# Players names\n",
    "nomes_jog = [] # List that will receive all the players names - check\n",
    "tags_nomes = pagina_bs.find_all(\"span\", {\"class\": \"show-for-small\"})\n",
    "for tag_nome in tags_nomes:\n",
    "    nomes_jog.append(tag_nome.text)\n",
    "\n",
    "# Players links\n",
    "links_jog = [] # List that will receive all the players profile links - check\n",
    "tags_links = BeautifulSoup(str(tags_nomes).strip('[]'), 'html.parser')\n",
    "for a in tags_links.find_all('a', href=True):\n",
    "    links_jog.append(a['href'])\n",
    "\n",
    "# Players Values links\n",
    "links_values_jog = []\n",
    "for link in links_jog:\n",
    "    links_values_jog.append(str(link).replace(\"profil\",\"marktwertverlauf\"))\n",
    "\n",
    "\n",
    "# Clubs championship\n",
    "camp_jog = []\n",
    "tags_camp = pagina_bs.find_all(\"span\", {\"class\": \"hauptpunkt\"})\n",
    "for tag_camp in tags_camp:\n",
    "    camp = str(tag_camp.text).replace(\" \", \"\").replace(\"\\n\",\"\")\n",
    "\n",
    "for c in range(len(nomes_jog)):\n",
    "    camp_jog.append(camp)\n",
    "\n",
    "# Players Positions\n",
    "posicoes_jog = [] # List that will receive all the players positions - check\n",
    "tags_goleiros = pagina_bs.find_all(\"td\", {\"class\": \"zentriert rueckennummer bg_Torwart\"})\n",
    "tags_zagueiros = pagina_bs.find_all(\"td\", {\"class\": \"zentriert rueckennummer bg_Abwehr\"})\n",
    "tags_meias = pagina_bs.find_all(\"td\", {\"class\": \"zentriert rueckennummer bg_Mittelfeld\"})\n",
    "tags_atacantes = pagina_bs.find_all(\"td\", {\"class\": \"zentriert rueckennummer bg_Sturm\"})\n",
    "\n",
    "# Gk positions\n",
    "for c in range(len(tags_goleiros)):\n",
    "    posicoes_jog.append(\"Goleiro\")\n",
    "\n",
    "# Defenders positions\n",
    "for c in range(len(tags_zagueiros)):\n",
    "    posicoes_jog.append(\"Defensor\")\n",
    "\n",
    "# Midfielders positions\n",
    "for c in range(len(tags_meias)):\n",
    "    posicoes_jog.append(\"Meia\")\n",
    "\n",
    "# Strikers positions\n",
    "for c in range(len(tags_atacantes)):\n",
    "    posicoes_jog.append(\"Atacante\")\n",
    "\n",
    "# # Players age, heights, nacionalities\n",
    "# idade_jog = [] # List that will receive all the players age - check\n",
    "# alt_jog = [] # List that will receive all the players height - check\n",
    "# nac_jog = [] # List that will receive all the players nacionalities - check\n",
    "\n",
    "# for link in links_jog:\n",
    "#     end = transfmkt_site + link\n",
    "#     obj_resp = requests.get(end, headers=headers)\n",
    "#     pag_bs = BeautifulSoup(obj_resp.content, 'html.parser')\n",
    "#     tags_idades = pag_bs.find_all(\"span\", {\"itemprop\": \"birthDate\"})\n",
    "#     tags_nac = pag_bs.find_all(\"span\", {\"itemprop\": \"nationality\"})\n",
    "#     tags_alt = pag_bs.find_all(\"span\", {\"itemprop\": \"height\"})\n",
    "#     for tag_idade in tags_idades:\n",
    "#         idade_jog.append(str(tag_idade.text).replace(\" \", \"\")[12:14])\n",
    "\n",
    "#     for tag_nac in tags_nac:\n",
    "#         nac_jog.append(str(tag_nac.text).replace(\" \", \"\")[1:])\n",
    "\n",
    "#     for tag_alt in tags_alt:\n",
    "#         alt_jog.append(float(str(tag_alt.text).replace(\",\",\".\")[:5].rstrip()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/jori/marktwertverlauf/spieler/429799',\n",
       " '/airton/marktwertverlauf/spieler/377799',\n",
       " '/matheus-cavichioli/marktwertverlauf/spieler/54274',\n",
       " '/robson/marktwertverlauf/spieler/902033',\n",
       " '/german-conti/marktwertverlauf/spieler/284321',\n",
       " '/iago-maidana/marktwertverlauf/spieler/348261',\n",
       " '/eder/marktwertverlauf/spieler/375690',\n",
       " '/luan-patrick/marktwertverlauf/spieler/658674',\n",
       " '/ricardo-silva/marktwertverlauf/spieler/206097',\n",
       " '/marlon-lopes/marktwertverlauf/spieler/443721',\n",
       " '/danilo-avelar/marktwertverlauf/spieler/140748',\n",
       " '/joao-paulo/marktwertverlauf/spieler/167471',\n",
       " '/patric/marktwertverlauf/spieler/95087',\n",
       " '/raul-caceres/marktwertverlauf/spieler/147410',\n",
       " '/ze-ricardo/marktwertverlauf/spieler/476336',\n",
       " '/lucas-kal/marktwertverlauf/spieler/435489',\n",
       " '/juninho/marktwertverlauf/spieler/271187',\n",
       " '/flavio/marktwertverlauf/spieler/672618',\n",
       " '/gustavinho/marktwertverlauf/spieler/800649',\n",
       " '/martin-benitez/marktwertverlauf/spieler/189418',\n",
       " '/juan-pablo-ramirez/marktwertverlauf/spieler/446850',\n",
       " '/matheusinho/marktwertverlauf/spieler/401533',\n",
       " '/aletm/marktwertverlauf/spieler/543614',\n",
       " '/emmanuel-martinez/marktwertverlauf/spieler/360526',\n",
       " '/everaldo/marktwertverlauf/spieler/388397',\n",
       " '/felipe-azevedo/marktwertverlauf/spieler/75111',\n",
       " '/carlos-alberto/marktwertverlauf/spieler/727747',\n",
       " '/gonzalo-mastriani/marktwertverlauf/spieler/195882',\n",
       " '/henrique-almeida/marktwertverlauf/spieler/103743',\n",
       " '/wellington-paulista/marktwertverlauf/spieler/51716',\n",
       " '/aloisio/marktwertverlauf/spieler/55246']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(nomes_jog, len(nomes_jog))\n",
    "# print(posicoes_jog, len(posicoes_jog))\n",
    "# print(idade_jog, len(idade_jog))\n",
    "# print(nac_jog, len(nac_jog))\n",
    "# print(alt_jog, len(alt_jog))\n",
    "links_values_jog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gr√°fico interativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "import chromedriver_binary\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "# Opening the connection and grabbing the page\n",
    "my_url = 'https://www.google.com/webhp?hl=en'\n",
    "option = Options()\n",
    "option.headless = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Xvfb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gabriel/projetos/github/TCC/0_exploracao_dados.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gabriel/projetos/github/TCC/0_exploracao_dados.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyvirtualdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m Display\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gabriel/projetos/github/TCC/0_exploracao_dados.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m display \u001b[39m=\u001b[39m Display(visible\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, size\u001b[39m=\u001b[39;49m(\u001b[39m800\u001b[39;49m, \u001b[39m800\u001b[39;49m))  \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gabriel/projetos/github/TCC/0_exploracao_dados.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m display\u001b[39m.\u001b[39mstart()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gabriel/projetos/github/TCC/0_exploracao_dados.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39mChrome(executable_path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/home/gabriel/.local/bin/chromedriver\u001b[39m\u001b[39m'\u001b[39m,options\u001b[39m=\u001b[39moption)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyvirtualdisplay/display.py:54\u001b[0m, in \u001b[0;36mDisplay.__init__\u001b[0;34m(self, backend, visible, size, color_depth, bgcolor, use_xauth, retries, extra_args, manage_global_env, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcls\u001b[39m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munknown backend: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend)\n\u001b[0;32m---> 54\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m     55\u001b[0m     size\u001b[39m=\u001b[39;49msize,\n\u001b[1;32m     56\u001b[0m     color_depth\u001b[39m=\u001b[39;49mcolor_depth,\n\u001b[1;32m     57\u001b[0m     bgcolor\u001b[39m=\u001b[39;49mbgcolor,\n\u001b[1;32m     58\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m     59\u001b[0m     use_xauth\u001b[39m=\u001b[39;49muse_xauth,\n\u001b[1;32m     60\u001b[0m     \u001b[39m# check_startup=check_startup,\u001b[39;49;00m\n\u001b[1;32m     61\u001b[0m     extra_args\u001b[39m=\u001b[39;49mextra_args,\n\u001b[1;32m     62\u001b[0m     manage_global_env\u001b[39m=\u001b[39;49mmanage_global_env,\n\u001b[1;32m     63\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     64\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyvirtualdisplay/xvfb.py:44\u001b[0m, in \u001b[0;36mXvfbDisplay.__init__\u001b[0;34m(self, size, color_depth, bgcolor, use_xauth, fbdir, dpi, retries, extra_args, manage_global_env)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fbdir \u001b[39m=\u001b[39m fbdir\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dpi \u001b[39m=\u001b[39m dpi\n\u001b[0;32m---> 44\u001b[0m AbstractDisplay\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     45\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m     46\u001b[0m     PROGRAM,\n\u001b[1;32m     47\u001b[0m     use_xauth\u001b[39m=\u001b[39;49muse_xauth,\n\u001b[1;32m     48\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m     49\u001b[0m     extra_args\u001b[39m=\u001b[39;49mextra_args,\n\u001b[1;32m     50\u001b[0m     manage_global_env\u001b[39m=\u001b[39;49mmanage_global_env,\n\u001b[1;32m     51\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyvirtualdisplay/abstractdisplay.py:85\u001b[0m, in \u001b[0;36mAbstractDisplay.__init__\u001b[0;34m(self, program, use_xauth, retries, extra_args, manage_global_env)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_wfd \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retries_current \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 85\u001b[0m helptext \u001b[39m=\u001b[39m get_helptext(program)\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_displayfd \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-displayfd\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m helptext\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_displayfd:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyvirtualdisplay/util.py:13\u001b[0m, in \u001b[0;36mget_helptext\u001b[0;34m(program)\u001b[0m\n\u001b[1;32m      6\u001b[0m cmd \u001b[39m=\u001b[39m [program, \u001b[39m\"\u001b[39m\u001b[39m-help\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[39m# py3.7+\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# p = subprocess.run(cmd, capture_output=True)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# stderr = p.stderr\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[39m# py3.6 also\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m p \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(\n\u001b[1;32m     14\u001b[0m     cmd,\n\u001b[1;32m     15\u001b[0m     stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[1;32m     16\u001b[0m     stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[1;32m     17\u001b[0m     shell\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m _, stderr \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mcommunicate()\n\u001b[1;32m     21\u001b[0m helptext \u001b[39m=\u001b[39m stderr\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:969\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[1;32m    966\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    967\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 969\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    970\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    971\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    972\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    973\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    974\u001b[0m                         errread, errwrite,\n\u001b[1;32m    975\u001b[0m                         restore_signals,\n\u001b[1;32m    976\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    977\u001b[0m                         start_new_session)\n\u001b[1;32m    978\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1845\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1843\u001b[0m     \u001b[39mif\u001b[39;00m errno_num \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1844\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1845\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1846\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Xvfb'"
     ]
    }
   ],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(800, 800))  \n",
    "display.start()\n",
    "driver = webdriver.Chrome(executable_path='/home/gabriel/.local/bin/chromedriver',options=option)\n",
    "driver.get(my_url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "import undetected_chromedriver as webdriver\n",
    "\n",
    "def force_patcher_to_use(directory):\n",
    "    # copy the chromedriver in directory\n",
    "    exe = webdriver.Patcher.exe_name\n",
    "    executable_path = os.path.join(directory, exe)\n",
    "    src = os.path.join(webdriver.Patcher.data_path, exe)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copyfile(src, executable_path)\n",
    "\n",
    "    # monkey patch the Patcher class\n",
    "    class PatcherWithForcedExecutablePath(webdriver.Patcher):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            kwargs[\"executable_path\"] = executable_path\n",
    "            super().__init__(*args, **kwargs)\n",
    "\n",
    "            # download the chromedriver if it was not already done above\n",
    "            if not os.path.exists(executable_path):\n",
    "                release = self.fetch_release_number()\n",
    "                self.version_main = release.version[0]\n",
    "                self.version_full = release\n",
    "                self.unzip_package(self.fetch_package())\n",
    "\n",
    "    webdriver.Patcher = PatcherWithForcedExecutablePath\n",
    "    return executable_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gabriel/.local/lib/python3.10/site-packages/chromedriver_binary/chromedriver'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "force_patcher_to_use('/home/gabriel/.local/lib/python3.10/site-packages/chromedriver_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
